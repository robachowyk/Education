{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "data_challenge_kernel_robach.py",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nz1319elcOmo"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "from matplotlib import pyplot as plt\n",
        "import torch\n",
        "from scipy import optimize\n",
        "\n",
        "################################################################################\n",
        "\n",
        "# INSTRUCTIONS\n",
        "# the 3 datasets should be saved in a \"data\" folder\n",
        "\n",
        "# load data\n",
        "Xtr = np.array(pd.read_csv(os.path.join('data','Xtr.csv'),header=None,sep=',',usecols=range(3072)))\n",
        "Xte = np.array(pd.read_csv(os.path.join('data','Xte.csv'),header=None,sep=',',usecols=range(3072)))\n",
        "Ytr = np.array(pd.read_csv(os.path.join('data','Ytr.csv'),sep=',',usecols=[1])).squeeze()\n",
        "\n",
        "################################################################################\n",
        "\n",
        "# transform data\n",
        "XTRR = Xtr.copy()\n",
        "XTRR = XTRR.reshape(Xtr.shape[0],3,32,32)\n",
        "XTRR = np.swapaxes(np.swapaxes(XTRR, 1, 2), 2, 3)\n",
        "XTRR = ( XTRR - XTRR.min() )/( XTRR.max() - XTRR.min() )\n",
        "\n",
        "# compute gradients of the image matrix\n",
        "XTRR_y = np.gradient(XTRR, axis=1)\n",
        "XTRR_x = np.gradient(XTRR, axis=2)\n",
        "\n",
        "# compute oriented gradients\n",
        "orientation_XTRR = np.rad2deg( np.arctan( XTRR_y / (XTRR_x + 1e-8) ) ) % 180\n",
        "\n",
        "# compute the image histogram\n",
        "new_Xtr = np.zeros( (Xtr.shape[0], 3*64) )\n",
        "for img in range(len(XTRR)):\n",
        "    new_Xtr[img] = np.array([ np.histogram(XTRR[img][:, :, _], bins=64)[0] for _ in range(3) ]).reshape(1,-1)\n",
        "\n",
        "# compute the oriented gradients image histogram\n",
        "new_Xtr_orientation = np.zeros( (Xtr.shape[0], 3*64) )\n",
        "for img in range(len(orientation_XTRR)):\n",
        "    new_Xtr_orientation[img] = np.array([ np.histogram(orientation_XTRR[img][:, :, _], bins=64)[0] for _ in range(3) ]).reshape(1,-1)\n",
        "\n",
        "# concatenate both for the input data\n",
        "NEW_XTR = np.concatenate((new_Xtr, new_Xtr_orientation), axis=1)  \n",
        "\n",
        "XTEE = Xte.copy()\n",
        "XTEE = XTEE.reshape(Xte.shape[0],3,32,32)\n",
        "XTEE = np.swapaxes(np.swapaxes(XTEE, 1, 2), 2, 3)\n",
        "XTEE = ( XTEE - XTEE.min() )/( XTEE.max() - XTEE.min() )\n",
        "\n",
        "XTEE_y = np.gradient(XTEE, axis=1)\n",
        "XTEE_x = np.gradient(XTEE, axis=2)\n",
        "\n",
        "orientation_XTEE = np.rad2deg( np.arctan( XTEE_y / (XTEE_x + 1e-8) ) ) % 180\n",
        "\n",
        "new_Xte = np.zeros( (Xte.shape[0], 3*64) )\n",
        "for img in range(len(XTEE)):\n",
        "    new_Xte[img] = np.array([ np.histogram(XTEE[img][:, :, _], bins=64)[0] for _ in range(3) ]).reshape(1,-1)\n",
        "\n",
        "new_Xte_orientation = np.zeros( (Xte.shape[0], 3*64) )\n",
        "for img in range(len(orientation_XTEE)):\n",
        "    new_Xte_orientation[img] = np.array([ np.histogram(orientation_XTEE[img][:, :, _], bins=64)[0] for _ in range(3) ]).reshape(1,-1)\n",
        "\n",
        "NEW_XTE = np.concatenate((new_Xte, new_Xte_orientation), axis=1)\n",
        "\n",
        "################################################################################\n",
        "\n",
        "# 3 kernels that seem suitable for image classification task\n",
        "\n",
        "class GeneralizedHistogramIntersectionKernel():\n",
        "    def __init__(self, beta):\n",
        "        self.beta = beta\n",
        "    def kernel(self,X,Y):\n",
        "        K = np.zeros((X.shape[0], Y.shape[0]))\n",
        "        N = X.shape[1]\n",
        "        # histogram intersection kernel = min kernel\n",
        "        for i in range(N):\n",
        "            K = K + np.minimum( (abs(X[:, i])**self.beta).reshape(-1, 1), (abs(Y[:, i])**self.beta).reshape(-1, 1).T )\n",
        "        return K\n",
        "\n",
        "class HistogramIntersectionKernel():\n",
        "    def __init__(self):\n",
        "        pass\n",
        "    def kernel(self,X,Y):\n",
        "        K = np.zeros((X.shape[0], Y.shape[0]))\n",
        "        N = X.shape[1]\n",
        "        # histogram intersection kernel = min kernel\n",
        "        for i in range(N):\n",
        "            K = K + np.minimum(X[:, i].reshape(-1, 1), Y[:, i].reshape(-1, 1).T)\n",
        "        return K\n",
        "\n",
        "class LogKernel():\n",
        "    def __init__(self, d):\n",
        "        self.d = d\n",
        "    def kernel(self, X, Y):\n",
        "        X = torch.tensor(X)\n",
        "        Y = torch.tensor(Y)\n",
        "        return (- torch.log( torch.cdist(X,Y)**self.d + 1 )).numpy()\n",
        "\n",
        "################################################################################\n",
        "\n",
        "# binary classification kernel SVM adaptation to multiple classes\n",
        "class KernelSVC:\n",
        "    \n",
        "    def __init__(self, C, kernel, epsilon = 1e-3):\n",
        "        self.C = C                               \n",
        "        self.kernel = kernel        \n",
        "        self.alpha = None\n",
        "        self.epsilon = epsilon\n",
        "       \n",
        "    def fit(self, X, y):\n",
        "        N = len(y)\n",
        "        K = self.kernel(X,X)\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "\n",
        "        def loss(alpha):\n",
        "            return 1./2 * np.linalg.multi_dot([alpha.T, np.diag(y), K, np.diag(y), alpha]) - alpha.T.dot(np.ones(N))\n",
        "        \n",
        "        def grad_loss(alpha):\n",
        "            return np.linalg.multi_dot([np.diag(y), K, np.diag(y), alpha]) - np.ones(N)\n",
        "\n",
        "        # function defining the equality constraint\n",
        "        fun_eq = lambda alpha: - alpha.T.dot(y)\n",
        "        \n",
        "        # jacobian wrt alpha of the equality constraint\n",
        "        jac_eq = lambda alpha: - y\n",
        "        \n",
        "        # function defining the inequality constraint\n",
        "        fun_ineq1 = lambda alpha: self.C*np.ones(N) - alpha\n",
        "        fun_ineq2 = lambda alpha: alpha\n",
        "        \n",
        "        # jacobian wrt alpha of the  inequality constraint\n",
        "        jac_ineq1 = lambda alpha: - np.eye(N)\n",
        "        jac_ineq2 = lambda alpha: np.eye(N)\n",
        "        \n",
        "        constraints = ({'type': 'eq', 'fun': fun_eq, 'jac': jac_eq},\n",
        "                       {'type': 'ineq', 'fun': fun_ineq1, 'jac': jac_ineq1},\n",
        "                       {'type': 'ineq', 'fun': fun_ineq2, 'jac': jac_ineq2})\n",
        "\n",
        "        optRes = optimize.minimize(fun=lambda alpha: loss(alpha),\n",
        "                                   x0=np.ones(N), \n",
        "                                   method='SLSQP', \n",
        "                                   jac=lambda alpha: grad_loss(alpha), \n",
        "                                   constraints=constraints)\n",
        "      \n",
        "        self.alpha = optRes.x \n",
        "\n",
        "        # A matrix with each row corresponding to a support vector\n",
        "        supportIndices = np.asarray( (constraints[1][\"fun\"](self.alpha) > self.epsilon)&(constraints[2][\"fun\"](self.alpha) > self.epsilon) ).nonzero()\n",
        "        self.support = X[supportIndices] \n",
        "        \n",
        "        # offset of the classifier\n",
        "        self.b = ( y[supportIndices] - (self.alpha.T @ np.diag(y) @ K)[supportIndices] ).mean()\n",
        "\n",
        "    def separating_function(self,x):\n",
        "        return self.alpha.T @ np.diag(self.y) @ self.kernel(self.X, x)\n",
        "    \n",
        "    def predict(self, X):\n",
        "        d = self.separating_function(X)\n",
        "        return d + self.b\n",
        "\n",
        "class MultiKernelSVC:\n",
        "\n",
        "    def __init__(self, kernel, C, epsilon=1e-3):\n",
        "        self.C = C        \n",
        "        self.kernel = kernel        \n",
        "        self.epsilon = epsilon\n",
        "        self.SVC_classifiers = []\n",
        "       \n",
        "    def fit(self, X, y):\n",
        "        self.X = X\n",
        "        self.n_classes = len(np.unique(y))\n",
        "        for c in np.unique(y):\n",
        "\n",
        "          id_class = np.asarray( y == c ).nonzero()[0]\n",
        "          id_other = np.random.choice( np.asarray( y != c ).nonzero()[0], size = len(id_class), replace = False )\n",
        "\n",
        "          Y = np.zeros( y.shape )\n",
        "          Y[ id_class ] = 1\n",
        "          Y[ id_other ] = -1\n",
        "          new_X = X[Y!=0]\n",
        "          new_Y = Y[Y!=0]\n",
        "\n",
        "          classifier = KernelSVC(self.C, self.kernel, self.epsilon)\n",
        "          classifier.fit(new_X, new_Y)\n",
        "          self.SVC_classifiers.append(classifier)\n",
        "    \n",
        "    def predict(self, x):\n",
        "        proba_prediction = np.array([clf.predict(x) for clf in self.SVC_classifiers]).T\n",
        "        prediction = np.argmax(proba_prediction, axis=1)\n",
        "        return prediction\n",
        "\n",
        "################################################################################\n",
        "\n",
        "# submission\n",
        "\n",
        "best_kernel = LogKernel(3).kernel\n",
        "best_C_value = 10\n",
        "\n",
        "kernel_svc = MultiKernelSVC(kernel = best_kernel, C = best_C_value)\n",
        "kernel_svc.fit(NEW_XTR, Ytr)\n",
        "Yte = kernel_svc.predict(NEW_XTE)\n",
        "\n",
        "Yte = {'Prediction' : Yte}\n",
        "dataframe = pd.DataFrame(Yte)\n",
        "dataframe.index += 1\n",
        "dataframe.to_csv('Yte_pred.csv', index_label='Id')"
      ]
    }
  ]
}